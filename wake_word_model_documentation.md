
# WakeWordModel Documentation

## Описание

Этот модуль представляет собой нейронную сеть для распознавания "пробуждающих слов" (wake word), обученную на аудиофайлах. Модель принимает аудиофайлы в формате WAV, извлекает признаки с помощью свёрточных слоев и временных зависимостей через GRU, и классифицирует их для выявления пробуждающего слова.

## Принцип работы

1. **Предобработка аудио**:
    - Входное аудио преобразуется в мел-спектрограмму с использованием функции `MelSpectrogram` из библиотеки `torchaudio`.
    - Если аудио в стерео, оно конвертируется в моно.
    - Проводится ресемплинг, если частота дискретизации аудио отличается от целевой.
    - Выполняется нормализация и дополнение или обрезка аудио до фиксированной длины.

2. **Аугментация**:
    - В обучении используется аугментация, включающая маскировку во временной и частотной областях, а также растяжение времени.

3. **Извлечение признаков**:
    - Свёрточные слои извлекают пространственные признаки из мел-спектрограммы, что позволяет модели выявлять важные аудиопризнаки, такие как временные шаблоны и частотные характеристики.

4. **Обработка временных зависимостей**:
    - Для анализа зависимостей во времени используется слой GRU, который помогает модели учитывать контекст из предыдущих временных шагов.

5. **Классификация**:
    - Модель производит классификацию с использованием полносвязного слоя, который принимает скрытые признаки из GRU и предсказывает, является ли аудио пробуждающим словом или нет.

## Структура модели

### 1. Мел-спектрограмма:
   Мел-спектрограмма используется для преобразования аудио-сигнала в частотные характеристики. Это основной способ представления аудио данных, который помогает модели выделить важные признаки для дальнейшей классификации.

### 2. Аугментация:
   Включает в себя различные трансформации, такие как:
   - **TimeStretch**: растяжка времени аудио сигнала.
   - **FrequencyMasking**: маскировка частотных компонентов.
   - **TimeMasking**: маскировка временных компонент.

### 3. Свёрточные слои:
   Используются для извлечения признаков из мел-спектрограммы, что помогает модели фокусироваться на важных паттернах, таких как звуковые особенности пробуждающего слова.

### 4. GRU слой:
   GRU (Gated Recurrent Unit) используется для обработки временных зависимостей. Это позволяет модели учитывать контекст на разных временных отрезках.

### 5. Классификация:
   Модель классифицирует аудио как "пробуждающее слово" или "не пробуждающее слово" с использованием полносвязного слоя.

## Методы

### 1. `preprocess_audio(audio_input, sr=None, augment=False)`
   Преобразует аудиофайл в мел-спектрограмму с последующей нормализацией и аугментацией.

   **Параметры**:
   - `audio_input`: Аудиофайл в формате WAV или тензор.
   - `sr`: Частота дискретизации аудио.
   - `augment`: Флаг для включения аугментации.

   **Возвращает**:
   - Мел-спектрограмму в децибелах с нормализацией.

### 2. `forward(x, input_is_raw=False, sr=None)`
   Основной метод для выполнения прямого прохода модели.

   **Параметры**:
   - `x`: Входные данные (аудиофайл или спектрограмма).
   - `input_is_raw`: Флаг, если входные данные — это необработанный аудиофайл.
   - `sr`: Частота дискретизации.

   **Возвращает**:
   - Логарифмическую вероятность для каждого класса.

### 3. `train_step(model, data, labels, optimizer, criterion, device)`
   Один шаг обучения модели.

   **Параметры**:
   - `model`: Модель для обучения.
   - `data`: Входные данные.
   - `labels`: Мишени для обучения.
   - `optimizer`: Оптимизатор для обновления весов.
   - `criterion`: Функция потерь.
   - `device`: Устройство для вычислений (например, 'cuda' или 'cpu').

   **Возвращает**:
   - Значение потери.

### 4. `predict(model, audio_input, sr=None, device='cpu')`
   Функция для предсказания класса для заданного аудиофайла.

   **Параметры**:
   - `model`: Обученная модель.
   - `audio_input`: Аудиофайл для классификации.
   - `sr`: Частота дискретизации аудио.
   - `device`: Устройство для вычислений (например, 'cpu' или 'cuda').

   **Возвращает**:
   - Предсказанный класс и уверенность в предсказании.

### 5. `get_files_and_classes(directory)`
   Функция для получения списка файлов и их классов из папки.

   **Параметры**:
   - `directory`: Папка, в которой находятся аудиофайлы.

   **Возвращает**:
   - Список путей файлов и их соответствующих классов.

## Пример использования

```python
# Создание экземпляра модели
model = WakeWordModel()

# Обучение модели
for epoch in range(num_epochs):
    for data, labels in data_loader:
        loss = train_step(model, data, labels, optimizer, criterion, device)

# Предсказание
audio_input = 'path/to/audio.wav'
predicted_class, confidence = predict(model, audio_input, device='cpu')

print(f"Predicted Class: {predicted_class}, Confidence: {confidence}")
```

## Требования

- `torch`
- `torchaudio`
- `numpy`
- `os`

## Лицензия

Этот проект распространяется под лицензией MIT.
